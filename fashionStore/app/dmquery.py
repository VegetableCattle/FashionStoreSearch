# -*- coding: utf-8 -*-
"""DMQuery.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18vuzI5zvTqTCMVu1yedO2Dl-JV2-uzh_
"""


#from google.colab import drive
#drive.mount('/content/drive')

import nltk
nltk.download('stopwords')

from collections import defaultdict
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from array import array
#from tqdm import tqdm
import csv
#from tqdm import tqdm
import copy
import re
import os
from functools import reduce
from enum import Enum
from docRetriever import DocRetriever


MAX_NO_RESULT = 20


MY_DRIVE = ''#'/content/drive/My Drive/Data Mining'

STYLE_WITH_DESC_N_TITLE = MY_DRIVE+'/styles_with_description_title.csv'

INVERTED_IDX_FILE = MY_DRIVE+'/home/anur0nArm/fashionStore/app/store_index.dat'

import os

print(os.getcwd())

class QueryType(Enum):
  OWQ = 1
  FTQ = 2
  PhQ = 3


class QueryHandler():
  def __init__(self):
    self.index={}

  def readIndex(self):
    file=open(self.indexFile, 'r')
    for line in file:
      line=line.rstrip()
      term, postings = line.split('|')    #term='termID', postings='docID1:pos1,pos2;docID2:pos1,pos2'
      postings=postings.split(';')        #postings=['docId1:pos1,pos2','docID2:pos1,pos2']
      postings=[x.split(':') for x in postings] #postings=[['docId1', 'pos1,pos2'], ['docID2', 'pos1,pos2']]
      postings=[ [int(x[0]), map(int, x[1].split(','))] for x in postings ]   #final postings list
      self.index[term]=postings
    file.close()
    print('Index loaded\n')
    print(len(self.index))
    print('Index loading complete')

  def prepareParams(self):
    self.stopwords = set(stopwords.words('english'))
    self.dataFile = STYLE_WITH_DESC_N_TITLE
    self.indexFile = INVERTED_IDX_FILE
    self.stemmer = PorterStemmer()

  def detectQueryType(self, query):
    if '"' in query:
      return QueryType.PhQ
    elif len(query.split()) > 1:
      return QueryType.FTQ
    else:
      return QueryType.OWQ

  def getTerms(self, doc):
    #print('Original\n'+doc)
    doc = doc.lower()
    #print('lowered\n\n'+doc)
    doc = re.sub(r'[^a-z0-9 ]',' ',doc) #put spaces instead of non-alphanumeric characters
    terms = doc.split()

    terms = [term for term in terms if term not in self.stopwords]
    terms = [self.stemmer.stem(term) for term in terms]
    #print('Terms:\n\n')
    #print(terms)
    return terms


  def performOneWordQuery(self, query):
    originalQuery = query
    query = self.getTerms(query)

    if len(query) == 0:
      print('Empty')
      return

    if len(query) > 1:
      self.performFreeTextQuery(originalQuery)
      return

    query = query[0]
    if query not in self.index:
      print('Not found')
    else:
      posting = self.index[query]
      posting = [x[0] for x in posting]
      posting =' '.join(map(str,posting))  #docid's are integers
      print(posting)
    return posting.split(' ')

  def performFreeTextQuery(self, query):
    query=self.getTerms(query)
    if len(query)==0:
      print('Empty')
      return

    print(query)
    docList=set()
    for term in query:
      print('Looking for '+term)
      try:
        posting = self.index[term]
        posting = [x[0] for x in posting]
        docList = docList | set(posting)
      except:
        #term not in index
        pass

    docList = list(docList)
    docList.sort()
    print(len(docList))
    #print(' '.join(map(str,docList)))
    if len(docList)==0:
      print('Not Found')
    return docList

  def getPostings(self, terms):
    #all terms in the list are guaranteed to be in the index
    return [ self.index[term] for term in terms ]

  def getDocsFromPostings(self, postings):
    #no empty list in postings
    return [ [x[0] for x in p] for p in postings ]

  def phraseQueryDocs(self, query):
    phraseDocs = []
    length = len(query)

    for term in query:
      if term not in self.index:
        return []
    postings = self.getPostings(query)
    docs = self.getDocsFromPostings(postings)
    docs = self.intersectLists(docs)

    for i in range(len(postings)):
      postings[i]=[x for x in postings[i] if x[0] in docs]

    postings = copy.deepcopy(postings)

    for i in range(len(postings)):
      for j in range(len(postings[i])):
        postings[i][j][1] = [x-i for x in postings[i][j][1]]

    result = []
    for i in range(len(postings[0])):
      docList = self.intersectLists([x[i][1] for x in postings])
      if docList == []:
        continue
      else:
        result.append(postings[0][i][0])

    return result


  def performPhraseQuery(self, query):
    originalQuery = query

    query = self.getTerms(query)
    if len(query) == 0:
      print('Empty')
      return

    phraseDocs = self.phraseQueryDocs(query)
    print(' '.join(map(str, phraseDocs)))
    if len(phraseDocs)==0:
      print('Not Found')
    return phraseDocs



  def intersectLists(self, lists):
    if len(lists) == 0:
        return []
    #start intersecting from the smaller list
    lists.sort(key=len)
    return list(reduce(lambda x,y: set(x)&set(y),lists))



  def performQuery(self, query):
    self.prepareParams()
    #self.readIndex()

    queryType = self.detectQueryType(query)

    docs = []

    if queryType == QueryType.OWQ:
      docs = self.performOneWordQuery(query)
    elif queryType == QueryType.FTQ:
      docs = self.performFreeTextQuery(query)
    elif queryType == QueryType.PhQ:
      docs = self.performPhraseQuery(query)
    docRetriever = DocRetriever()
    docs=[str(docs[i]) for i in range(min(MAX_NO_RESULT, len(docs)))]
    print(len(docs))
    docs = docRetriever.retrieveDocs(docs)

    return docs


if __name__ == '__main__':
  queryHandler = QueryHandler()
  queryHandler.prepareParams()
  queryHandler.readIndex()
  #docs = queryHandler.performQuery(' toy')

  #print(type(docs))

  #print(len(docs))

  #for doc in docs:
  # print(doc.displayName+'\n')
  #print('Search complete')
  #queryHandler.performQuery('shirt')
  print('Index loading complete')
